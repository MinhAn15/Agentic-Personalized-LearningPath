# üî¨ Deep Analysis: RAG vs GraphRAG Conflict Resolution

## üìù V·∫•n ƒë·ªÅ ƒë·∫∑t ra

Trong h·ªá th·ªëng 3-Layer Grounding c·ªßa Agent 4:
- **Layer 1 (RAG)**: Vector-based retrieval t·ª´ documents
- **Layer 2 (Course KG)**: Structured knowledge t·ª´ Neo4j
- **Layer 3 (Personal KG)**: Learner-specific data

**C√¢u h·ªèi**: N·∫øu 2 layers tr·∫£ v·ªÅ k·∫øt qu·∫£ kh√°c nhau ho·∫∑c m√¢u thu·∫´n, ta n√™n x·ª≠ l√Ω nh∆∞ th·∫ø n√†o?

---

## üß™ Scientific Research (2024-2025)

### 1. TruthfulRAG (2024)

**Ngu·ªìn**: ResearchGate - "TruthfulRAG: Using Knowledge Graphs for Factual Conflict Resolution"

**C∆° ch·∫ø**:
- Extract triples t·ª´ retrieved content
- Query Knowledge Graph ƒë·ªÉ verify
- **Entropy-based filtering** ƒë·ªÉ lo·∫°i b·ªè inconsistencies

**Insight**: KG ƒë∆∞·ª£c coi l√† **ground truth** v√¨ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c curated v√† validated.

### 2. HybGRAG (2024)

**Ngu·ªìn**: GraphRAG.com - Hybrid Graph-RAG for Semi-Structured Knowledge

**C∆° ch·∫ø**:
- **Retriever Bank**: Nhi·ªÅu retrievers song song
- **Critic Module**: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng t·ª´ng retrieval
- **Adaptive Selection**: Ch·ªçn retriever t·ªët nh·∫•t cho t·ª´ng query

### 3. Reciprocal Rank Fusion (RRF)

**Ngu·ªìn**: Medium - "Hybrid RAG: Merging Dense and Sparse Retrieval"

**Formula**:
```
RRF_score(d) = Œ£ 1 / (k + rank_i(d))
```

**C∆° ch·∫ø**: Combine rankings t·ª´ nhi·ªÅu retrievers, kh√¥ng d·ª±a v√†o absolute scores.

---

## üîç Systematic Problem Breakdown

### Scenario 1: Complementary Information (Kh√¥ng m√¢u thu·∫´n)

| Layer | Content |
|-------|---------|
| RAG | "SELECT is used to query data" |
| Course KG | Definition: "SELECT retrieves rows from tables" |
| Personal KG | Past error: "Confused SELECT with UPDATE" |

**K·∫øt lu·∫≠n**: **Merge all** - Th√¥ng tin b·ªï sung cho nhau.

### Scenario 2: Different Granularity (C√πng h∆∞·ªõng, kh√°c ƒë·ªô chi ti·∫øt)

| Layer | Content |
|-------|---------|
| RAG | "SQL is a query language" (general) |
| Course KG | "SELECT syntax: SELECT col FROM table WHERE..." (specific) |

**K·∫øt lu·∫≠n**: **Prioritize KG** - Structured knowledge c√≥ ƒë·ªô ch√≠nh x√°c cao h∆°n.

### Scenario 3: Direct Conflict (M√¢u thu·∫´n tr·ª±c ti·∫øp)

| Layer | Content |
|-------|---------|
| RAG | "NULL values can be compared with =" |
| Course KG | Misconception: "NULL = NULL returns FALSE, use IS NULL" |

**K·∫øt lu·∫≠n**: **Trust Course KG** - ƒê∆∞·ª£c curated b·ªüi Agent 1, ƒë√£ qua validation.

### Scenario 4: Outdated vs Current

| Layer | Content |
|-------|---------|
| RAG | "MySQL 5.7 syntax..." (old document) |
| Course KG | Current version info |

**K·∫øt lu·∫≠n**: **Use confidence scores** - Document v·ªõi low score s·∫Ω b·ªã downweight.

---

## üéØ Recommended Strategy: Hierarchical Trust

```
Trust Hierarchy:
1. Course KG (Curated, validated) - HIGHEST
2. Personal KG (Learner-specific context)
3. RAG (Raw documents) - LOWEST (may contain outdated/incorrect info)
```

### Why This Order?

| Layer | Pros | Cons |
|-------|------|------|
| **Course KG** | Curated by Agent 1, validated, structured | May miss edge cases |
| **Personal KG** | Personalized, tracks learner's specific errors | Limited scope |
| **RAG** | Broad coverage, detailed examples | May contain errors, outdated |

---

## üí° Implementation Recommendation

### Current System (Weight-based):
```python
confidence = 0.40 * doc_score + 0.35 * kg_score + 0.25 * personal_score
```

### Proposed Enhancement: Conflict-Aware Fusion

```python
def resolve_conflicts(doc_context, kg_context, personal_context):
    """
    TruthfulRAG-inspired conflict resolution.
    
    Strategy:
    1. If KG has `common_misconceptions` that match RAG content ‚Üí WARN
    2. If Personal has `past_errors` matching current topic ‚Üí PERSONALIZE
    3. Use KG as ground truth for factual claims
    """
    # Check if RAG content matches known misconceptions
    kg_misconceptions = kg_context.get("misconceptions", [])
    doc_chunks = doc_context.get("retrieved_chunks", [])
    
    conflicts = []
    for chunk in doc_chunks:
        for misconception in kg_misconceptions:
            if semantic_match(chunk, misconception):
                conflicts.append({
                    "source": "DOCUMENT",
                    "conflict_type": "MATCHES_MISCONCEPTION",
                    "content": chunk,
                    "correction": misconception
                })
    
    # Prioritize KG for definitions, use RAG for examples only
    return {
        "definition": kg_context.get("definition"),  # Always from KG
        "examples": doc_context.get("chunks", []),   # From RAG
        "warnings": conflicts,
        "personal_context": personal_context
    }
```

---

## üìä When to Use Each Layer

| Question Type | Primary Layer | Secondary | Reason |
|---------------|---------------|-----------|--------|
| "What is X?" | Course KG | RAG | Definition c·∫ßn ch√≠nh x√°c |
| "Give me examples" | RAG | Course KG | Documents c√≥ nhi·ªÅu examples |
| "I'm confused about..." | Personal KG | Course KG | Need learner's past errors |
| "What's the difference..." | Course KG | Course KG | Relationships are structured |

---

## ‚úÖ Final Recommendation

H·ªá th·ªëng 3-Layer **ƒë√£ t·ªëi ∆∞u** cho usecase n√†y v√¨:

1. **Complementary by Design**: M·ªói layer ph·ª•c v·ª• m·ª•c ƒë√≠ch kh√°c nhau
2. **Weights ph·∫£n √°nh trust**: KG (0.35) g·∫ßn b·∫±ng RAG (0.40) nh∆∞ng structured h∆°n
3. **Personal layer l√† differentiator**: Kh√¥ng th·ªÉ c√≥ t·ª´ RAG/KG thu·∫ßn

### Improvements Applied:
1. ‚úÖ Parallel execution (faster)
2. ‚úÖ Dynamic scoring (more accurate)
3. ‚úÖ Layer scores metadata (enables future conflict detection)

### Future Enhancement (TODO):
- Add semantic similarity check between RAG chunks and KG misconceptions
- Implement RRF-style ranking fusion
- Add confidence degradation over time for RAG content
